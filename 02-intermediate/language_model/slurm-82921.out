Loading pytorch-py37-cuda10.2-gcc/1.6.0
  Loading requirement: gcc5/5.5.0 cuda10.2/toolkit/10.2.89
    ml-pythondeps-py37-cuda10.2-gcc/4.3.3 cudnn7.6-cuda10.2/7.6.5.32
    nccl2-cuda10.2-gcc/2.6.4
ok!
Epoch [1/5], Step[0/1549], Loss: 9.2092, Perplexity: 9988.36
Epoch [1/5], Step[100/1549], Loss: 6.0020, Perplexity: 404.22
Epoch [1/5], Step[200/1549], Loss: 5.8846, Perplexity: 359.44
Epoch [1/5], Step[300/1549], Loss: 5.7407, Perplexity: 311.29
Epoch [1/5], Step[400/1549], Loss: 5.7035, Perplexity: 299.92
Epoch [1/5], Step[500/1549], Loss: 5.1275, Perplexity: 168.60
Epoch [1/5], Step[600/1549], Loss: 5.2133, Perplexity: 183.70
Epoch [1/5], Step[700/1549], Loss: 5.3295, Perplexity: 206.33
Epoch [1/5], Step[800/1549], Loss: 5.1500, Perplexity: 172.43
Epoch [1/5], Step[900/1549], Loss: 5.0630, Perplexity: 158.06
Epoch [1/5], Step[1000/1549], Loss: 5.1254, Perplexity: 168.23
Epoch [1/5], Step[1100/1549], Loss: 5.3906, Perplexity: 219.34
Epoch [1/5], Step[1200/1549], Loss: 5.2070, Perplexity: 182.55
Epoch [1/5], Step[1300/1549], Loss: 5.1318, Perplexity: 169.32
Epoch [1/5], Step[1400/1549], Loss: 4.8769, Perplexity: 131.22
Epoch [1/5], Step[1500/1549], Loss: 5.1236, Perplexity: 167.94
Epoch [2/5], Step[0/1549], Loss: 5.3908, Perplexity: 219.38
Epoch [2/5], Step[100/1549], Loss: 4.5589, Perplexity: 95.48
Epoch [2/5], Step[200/1549], Loss: 4.6891, Perplexity: 108.76
Epoch [2/5], Step[300/1549], Loss: 4.7369, Perplexity: 114.08
Epoch [2/5], Step[400/1549], Loss: 4.6062, Perplexity: 100.11
Epoch [2/5], Step[500/1549], Loss: 4.1657, Perplexity: 64.44
Epoch [2/5], Step[600/1549], Loss: 4.4233, Perplexity: 83.37
Epoch [2/5], Step[700/1549], Loss: 4.3814, Perplexity: 79.95
Epoch [2/5], Step[800/1549], Loss: 4.4465, Perplexity: 85.33
Epoch [2/5], Step[900/1549], Loss: 4.2052, Perplexity: 67.03
Epoch [2/5], Step[1000/1549], Loss: 4.3607, Perplexity: 78.31
Epoch [2/5], Step[1100/1549], Loss: 4.5261, Perplexity: 92.40
Epoch [2/5], Step[1200/1549], Loss: 4.5038, Perplexity: 90.36
Epoch [2/5], Step[1300/1549], Loss: 4.2814, Perplexity: 72.34
Epoch [2/5], Step[1400/1549], Loss: 4.0346, Perplexity: 56.52
Epoch [2/5], Step[1500/1549], Loss: 4.3047, Perplexity: 74.05
Epoch [3/5], Step[0/1549], Loss: 6.3034, Perplexity: 546.43
Epoch [3/5], Step[100/1549], Loss: 3.8553, Perplexity: 47.24
Epoch [3/5], Step[200/1549], Loss: 4.0533, Perplexity: 57.59
Epoch [3/5], Step[300/1549], Loss: 3.9944, Perplexity: 54.29
Epoch [3/5], Step[400/1549], Loss: 3.9212, Perplexity: 50.46
Epoch [3/5], Step[500/1549], Loss: 3.4105, Perplexity: 30.28
Epoch [3/5], Step[600/1549], Loss: 3.8883, Perplexity: 48.83
Epoch [3/5], Step[700/1549], Loss: 3.7065, Perplexity: 40.71
Epoch [3/5], Step[800/1549], Loss: 3.7918, Perplexity: 44.34
Epoch [3/5], Step[900/1549], Loss: 3.5284, Perplexity: 34.07
Epoch [3/5], Step[1000/1549], Loss: 3.6761, Perplexity: 39.49
Epoch [3/5], Step[1100/1549], Loss: 3.7670, Perplexity: 43.25
Epoch [3/5], Step[1200/1549], Loss: 3.8474, Perplexity: 46.87
Epoch [3/5], Step[1300/1549], Loss: 3.5106, Perplexity: 33.47
Epoch [3/5], Step[1400/1549], Loss: 3.3076, Perplexity: 27.32
Epoch [3/5], Step[1500/1549], Loss: 3.5217, Perplexity: 33.84
Epoch [4/5], Step[0/1549], Loss: 4.7180, Perplexity: 111.95
Epoch [4/5], Step[100/1549], Loss: 3.3423, Perplexity: 28.28
Epoch [4/5], Step[200/1549], Loss: 3.4928, Perplexity: 32.88
Epoch [4/5], Step[300/1549], Loss: 3.4584, Perplexity: 31.77
Epoch [4/5], Step[400/1549], Loss: 3.4181, Perplexity: 30.51
Epoch [4/5], Step[500/1549], Loss: 2.9441, Perplexity: 18.99
Epoch [4/5], Step[600/1549], Loss: 3.3667, Perplexity: 28.98
Epoch [4/5], Step[700/1549], Loss: 3.2740, Perplexity: 26.42
Epoch [4/5], Step[800/1549], Loss: 3.3242, Perplexity: 27.78
Epoch [4/5], Step[900/1549], Loss: 3.0506, Perplexity: 21.13
Epoch [4/5], Step[1000/1549], Loss: 3.1716, Perplexity: 23.84
Epoch [4/5], Step[1100/1549], Loss: 3.2105, Perplexity: 24.79
Epoch [4/5], Step[1200/1549], Loss: 3.3054, Perplexity: 27.26
Epoch [4/5], Step[1300/1549], Loss: 3.0344, Perplexity: 20.79
Epoch [4/5], Step[1400/1549], Loss: 2.7700, Perplexity: 15.96
Epoch [4/5], Step[1500/1549], Loss: 3.0765, Perplexity: 21.68
Epoch [5/5], Step[0/1549], Loss: 3.8504, Perplexity: 47.01
Epoch [5/5], Step[100/1549], Loss: 3.0302, Perplexity: 20.70
Epoch [5/5], Step[200/1549], Loss: 3.0721, Perplexity: 21.59
Epoch [5/5], Step[300/1549], Loss: 3.0756, Perplexity: 21.66
Epoch [5/5], Step[400/1549], Loss: 3.0420, Perplexity: 20.95
Epoch [5/5], Step[500/1549], Loss: 2.5890, Perplexity: 13.32
Epoch [5/5], Step[600/1549], Loss: 3.0649, Perplexity: 21.43
Epoch [5/5], Step[700/1549], Loss: 2.9758, Perplexity: 19.61
Epoch [5/5], Step[800/1549], Loss: 3.0039, Perplexity: 20.16
Epoch [5/5], Step[900/1549], Loss: 2.6699, Perplexity: 14.44
Epoch [5/5], Step[1000/1549], Loss: 2.8258, Perplexity: 16.87
Epoch [5/5], Step[1100/1549], Loss: 2.9287, Perplexity: 18.70
Epoch [5/5], Step[1200/1549], Loss: 3.0548, Perplexity: 21.22
Epoch [5/5], Step[1300/1549], Loss: 2.7525, Perplexity: 15.68
Epoch [5/5], Step[1400/1549], Loss: 2.4627, Perplexity: 11.74
Epoch [5/5], Step[1500/1549], Loss: 2.8073, Perplexity: 16.57
Sampled [100/1000] words and save to sample.txt
Sampled [200/1000] words and save to sample.txt
Sampled [300/1000] words and save to sample.txt
Sampled [400/1000] words and save to sample.txt
Sampled [500/1000] words and save to sample.txt
Sampled [600/1000] words and save to sample.txt
Sampled [700/1000] words and save to sample.txt
Sampled [800/1000] words and save to sample.txt
Sampled [900/1000] words and save to sample.txt
Sampled [1000/1000] words and save to sample.txt
